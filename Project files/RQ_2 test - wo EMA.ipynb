{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Okl2JnUUhr"
      },
      "source": [
        "# Vector-Quantized Variational Autoencoders\n",
        "\n",
        "**Author:** [Sayak Paul](https://twitter.com/RisingSayak)<br>\n",
        "**Date created:** 2021/07/21<br>\n",
        "**Last modified:** 2022/06/27<br>\n",
        "**Description:** Training a VQ-VAE for image reconstruction and codebook sampling for generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-3ZUN7rUUhy"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 390,
      "metadata": {
        "id": "-hu-GqEYUUhy"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-probability\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4Q3wR9iUUh0"
      },
      "source": [
        "**A note on straight-through estimation**:\n",
        "\n",
        "This line of code does the straight-through estimation part: `quantized = x +\n",
        "tf.stop_gradient(quantized - x)`. During backpropagation, `(quantized - x)` won't be\n",
        "included in the computation graph and the gradients obtained for `quantized`\n",
        "will be copied for `inputs`. Thanks to [this video](https://youtu.be/VZFVUrYcig0?t=1393)\n",
        "for helping me understand this technique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Residual "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualVectorQuantizer(layers.Layer):\n",
        "    def __init__(self, num_embeddings, embedding_dim, num_quantizers, beta=0.25, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.num_quantizers = num_quantizers  # Number of residual quantization stages\n",
        "        self.beta = beta\n",
        "\n",
        "        # Create multiple embedding matrices (one per quantization stage)\n",
        "        w_init =  tf.keras.initializers.RandomUniform()\n",
        "        self.embeddings = [\n",
        "            tf.Variable(\n",
        "                initial_value=w_init(\n",
        "                    shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"\n",
        "                ),\n",
        "                trainable=True,\n",
        "                name=f\"embeddings_vqvae_{i}\",\n",
        "            )\n",
        "            for i in range(self.num_quantizers)\n",
        "        ]\n",
        "\n",
        "    def call(self, x):\n",
        "        shape = tf.shape(x)  # Get dynamic shape\n",
        "        batch_size, height, width, channels = shape[0], shape[1], shape[2], shape[3]\n",
        "        flattened = tf.reshape(x, [batch_size * height * width, channels])\n",
        "\n",
        "        residual = flattened\n",
        "        quantized_output = tf.zeros_like(flattened)\n",
        "        total_commitment_loss = 0\n",
        "        total_codebook_loss = 0\n",
        "\n",
        "\n",
        "        for i in range(self.num_quantizers):\n",
        "         \n",
        "            encoding_indices = self.get_code_indices(residual, self.embeddings[i])\n",
        "            encodings = tf.one_hot(encoding_indices, self.num_embeddings)\n",
        "            quantized = tf.matmul(encodings, self.embeddings[i], transpose_b=True)\n",
        "\n",
        "            \n",
        "            # Compute loss\n",
        "            codebook_loss = tf.reduce_mean((tf.stop_gradient(residual) - quantized) ** 2)\n",
        "            commitment_loss = tf.reduce_mean((residual - tf.stop_gradient(quantized)) ** 2)\n",
        "            total_commitment_loss += commitment_loss\n",
        "            total_codebook_loss += codebook_loss\n",
        "\n",
        "            residual -= quantized\n",
        "            quantized_output += quantized\n",
        "    \n",
        "\n",
        "        total_loss = self.beta * total_commitment_loss + total_codebook_loss\n",
        "        self.add_loss(total_loss)\n",
        "\n",
        "        # Reshape back to (batch, height, width, channels)\n",
        "        quantized_output = tf.reshape(quantized_output, [batch_size, height, width, channels])\n",
        "\n",
        "        # Straight-through estimator\n",
        "        quantized_output = x + tf.stop_gradient(quantized_output - x)\n",
        "        return quantized_output\n",
        "\n",
        "    def get_code_indices(self, inputs, embedding_matrix):\n",
        "        # Calculate L2-normalized distance between inputs and codebook vectors\n",
        "        similarity = tf.matmul(inputs, embedding_matrix)\n",
        "        distances = (\n",
        "            tf.reduce_sum(inputs ** 2, axis=1, keepdims=True)\n",
        "            + tf.reduce_sum(embedding_matrix ** 2, axis=0)\n",
        "            - 2 * similarity\n",
        "        )\n",
        "\n",
        "        # Get the index of the nearest codebook vector\n",
        "        encoding_indices = tf.argmin(distances, axis=1)\n",
        "        return encoding_indices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-aVrzU_UUh1"
      },
      "source": [
        "## Encoder and decoder\n",
        "\n",
        "Now for the encoder and the decoder for the VQ-VAE. We will keep them small so\n",
        "that their capacity is a good fit for the MNIST dataset. The implementation of the encoder and\n",
        "come from\n",
        "[this example](https://keras.io/examples/generative/vae).\n",
        "\n",
        "Note that activations _other than ReLU_ may not work for the encoder and decoder layers in the\n",
        "quantization architecture: Leaky ReLU activated layers, for example, have proven difficult to\n",
        "train, resulting in intermittent loss spikes that the model has trouble recovering from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JujsUdT2UUh1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_encoder(latent_dim=16):\n",
        "    encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
        "    x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
        "        encoder_inputs\n",
        "    )\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    encoder_outputs = layers.Conv2D(latent_dim, 1, padding=\"same\")(x)\n",
        "    return keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n",
        "\n",
        "\n",
        "def get_decoder(latent_dim=16):\n",
        "    latent_inputs = keras.Input(shape=get_encoder(latent_dim).output.shape[1:])\n",
        "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
        "        latent_inputs\n",
        "    )\n",
        "    x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    decoder_outputs = layers.Conv2DTranspose(1, 3, padding=\"same\")(x)\n",
        "    return keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining RQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"rvq_vae\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"rvq_vae\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,076</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ vector_quantizer                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualVectorQuantizer</span>)       │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,121</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │        \u001b[38;5;34m19,076\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ vector_quantizer                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mResidualVectorQuantizer\u001b[0m)       │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │        \u001b[38;5;34m21,121\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,197</span> (157.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,197\u001b[0m (157.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,197</span> (157.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,197\u001b[0m (157.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "def get_vqvae(latent_dim=4, num_embeddings=64,num_quantizers =2):\n",
        "    rvq_layer = ResidualVectorQuantizer(num_embeddings, latent_dim,num_quantizers, name=\"vector_quantizer\")\n",
        "    encoder = get_encoder(latent_dim)\n",
        "    decoder = get_decoder(latent_dim)\n",
        "    inputs = keras.Input(shape=(28, 28, 1))\n",
        "    encoder_outputs = encoder(inputs)\n",
        "    quantized_latents = rvq_layer(encoder_outputs)\n",
        "    reconstructions = decoder(quantized_latents)\n",
        "    return keras.Model(inputs, reconstructions, name=\"rvq_vae\")\n",
        "\n",
        "get_vqvae().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwzLMWy6UUh3"
      },
      "source": [
        "## Wrapping up the training loop inside `RVQVAETrainer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QbfBDo8iUUh3"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RVQVAETrainer(keras.models.Model):\n",
        "    def __init__(self, train_variance, latent_dim=32, num_embeddings=128, num_quantizers = 2,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.train_variance = train_variance\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.num_quantizers = num_quantizers\n",
        "\n",
        "        self.rvqvae = get_vqvae(self.latent_dim, self.num_embeddings, self.num_quantizers)\n",
        "\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.rvq_loss_tracker = keras.metrics.Mean(name=\"rvq_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.rvq_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, x):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Outputs from the VQ-VAE.\n",
        "            reconstructions = self.rvqvae(x)\n",
        "\n",
        "            # Calculate the losses.\n",
        "            reconstruction_loss = (\n",
        "                tf.reduce_mean((x - reconstructions) ** 2) / self.train_variance\n",
        "            )\n",
        "            total_loss = reconstruction_loss + sum(self.rvqvae.losses)\n",
        "\n",
        "        # Backpropagation.\n",
        "        grads = tape.gradient(total_loss, self.rvqvae.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.rvqvae.trainable_variables))\n",
        "\n",
        "        # Loss tracking.\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.rvq_loss_tracker.update_state(sum(self.rvqvae.losses))\n",
        "\n",
        "        # Log results.\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"rvqvae_loss\": self.rvq_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5ljEADUUh4"
      },
      "source": [
        "## Load and preprocess the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST-R9nMNUUh4",
        "outputId": "bc130232-e750-4370-c910-7e9b9848418d"
      },
      "outputs": [],
      "source": [
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "x_train_scaled = (x_train / 255.0) - 0.5\n",
        "x_test_scaled = (x_test / 255.0) - 0.5\n",
        "\n",
        "data_variance = np.var(x_train / 255.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C2aF4jXUUh4"
      },
      "source": [
        "## Train the VQ-VAE model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5on6YX9UUh4",
        "outputId": "70b0de92-1b0b-4274-e3fb-fa90c602f212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - loss: 63.3384 - reconstruction_loss: 0.6546 - rvqvae_loss: 62.6838\n",
            "Epoch 2/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - loss: 263.3599 - reconstruction_loss: 0.1090 - rvqvae_loss: 263.2510\n",
            "Epoch 3/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 56ms/step - loss: 234.0476 - reconstruction_loss: 0.0864 - rvqvae_loss: 233.9612\n",
            "Epoch 4/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 65ms/step - loss: 238.2285 - reconstruction_loss: 0.0800 - rvqvae_loss: 238.1484\n",
            "Epoch 5/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 65ms/step - loss: 248.0072 - reconstruction_loss: 0.0740 - rvqvae_loss: 247.9333\n",
            "Epoch 6/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 70ms/step - loss: 250.5705 - reconstruction_loss: 0.0704 - rvqvae_loss: 250.5000\n",
            "Epoch 7/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 70ms/step - loss: 241.0984 - reconstruction_loss: 0.0678 - rvqvae_loss: 241.0306\n",
            "Epoch 8/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 68ms/step - loss: 252.0079 - reconstruction_loss: 0.0669 - rvqvae_loss: 251.9411\n",
            "Epoch 9/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 67ms/step - loss: 261.7375 - reconstruction_loss: 0.0656 - rvqvae_loss: 261.6719\n",
            "Epoch 10/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 66ms/step - loss: 275.0065 - reconstruction_loss: 0.0660 - rvqvae_loss: 274.9406\n",
            "Epoch 11/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 65ms/step - loss: 270.2771 - reconstruction_loss: 0.0643 - rvqvae_loss: 270.2128\n",
            "Epoch 12/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 67ms/step - loss: 268.7755 - reconstruction_loss: 0.0630 - rvqvae_loss: 268.7125\n",
            "Epoch 13/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 66ms/step - loss: 272.6436 - reconstruction_loss: 0.0621 - rvqvae_loss: 272.5815\n",
            "Epoch 14/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 67ms/step - loss: 260.2754 - reconstruction_loss: 0.0609 - rvqvae_loss: 260.2145\n",
            "Epoch 15/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 70ms/step - loss: 360.6935 - reconstruction_loss: 0.0783 - rvqvae_loss: 360.6152\n",
            "Epoch 16/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - loss: 284.9486 - reconstruction_loss: 0.0622 - rvqvae_loss: 284.8863\n",
            "Epoch 17/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 70ms/step - loss: 268.8003 - reconstruction_loss: 0.0604 - rvqvae_loss: 268.7398\n",
            "Epoch 18/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 68ms/step - loss: 263.3604 - reconstruction_loss: 0.0597 - rvqvae_loss: 263.3007\n",
            "Epoch 19/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 67ms/step - loss: 270.5714 - reconstruction_loss: 0.0607 - rvqvae_loss: 270.5105\n",
            "Epoch 20/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 71ms/step - loss: 263.1375 - reconstruction_loss: 0.0591 - rvqvae_loss: 263.0784\n",
            "Epoch 21/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 91ms/step - loss: 270.0993 - reconstruction_loss: 0.0599 - rvqvae_loss: 270.0395\n",
            "Epoch 22/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 68ms/step - loss: 267.6395 - reconstruction_loss: 0.0589 - rvqvae_loss: 267.5806\n",
            "Epoch 23/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 68ms/step - loss: 266.3510 - reconstruction_loss: 0.0585 - rvqvae_loss: 266.2925\n",
            "Epoch 24/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 68ms/step - loss: 261.5974 - reconstruction_loss: 0.0581 - rvqvae_loss: 261.5393\n",
            "Epoch 25/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 68ms/step - loss: 262.5911 - reconstruction_loss: 0.0578 - rvqvae_loss: 262.5333\n",
            "Epoch 26/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 65ms/step - loss: 270.5957 - reconstruction_loss: 0.0582 - rvqvae_loss: 270.5375\n",
            "Epoch 27/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - loss: 282.3719 - reconstruction_loss: 0.0586 - rvqvae_loss: 282.3133\n",
            "Epoch 28/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 72ms/step - loss: 285.2260 - reconstruction_loss: 0.0584 - rvqvae_loss: 285.1676\n",
            "Epoch 29/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 66ms/step - loss: 286.7721 - reconstruction_loss: 0.0580 - rvqvae_loss: 286.7141\n",
            "Epoch 30/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 71ms/step - loss: 289.7923 - reconstruction_loss: 0.0578 - rvqvae_loss: 289.7346\n",
            "Epoch 31/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 71ms/step - loss: 299.4254 - reconstruction_loss: 0.0590 - rvqvae_loss: 299.3665\n",
            "Epoch 32/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 72ms/step - loss: 286.1774 - reconstruction_loss: 0.0566 - rvqvae_loss: 286.1208\n",
            "Epoch 33/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 77ms/step - loss: 285.6423 - reconstruction_loss: 0.0563 - rvqvae_loss: 285.5861\n",
            "Epoch 34/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 72ms/step - loss: 286.9616 - reconstruction_loss: 0.0560 - rvqvae_loss: 286.9058\n",
            "Epoch 35/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - loss: 295.2224 - reconstruction_loss: 0.0562 - rvqvae_loss: 295.1663\n",
            "Epoch 36/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - loss: 298.9399 - reconstruction_loss: 0.0558 - rvqvae_loss: 298.8842\n",
            "Epoch 37/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 298.1854 - reconstruction_loss: 0.0557 - rvqvae_loss: 298.1297\n",
            "Epoch 38/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - loss: 299.8737 - reconstruction_loss: 0.0556 - rvqvae_loss: 299.8181\n",
            "Epoch 39/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - loss: 296.7287 - reconstruction_loss: 0.0554 - rvqvae_loss: 296.6733\n",
            "Epoch 40/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - loss: 297.7025 - reconstruction_loss: 0.0553 - rvqvae_loss: 297.6472\n",
            "Epoch 41/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 299.5550 - reconstruction_loss: 0.0553 - rvqvae_loss: 299.4997\n",
            "Epoch 42/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - loss: 300.5546 - reconstruction_loss: 0.0552 - rvqvae_loss: 300.4995\n",
            "Epoch 43/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - loss: 303.6579 - reconstruction_loss: 0.0552 - rvqvae_loss: 303.6028\n",
            "Epoch 44/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 301.2667 - reconstruction_loss: 0.0549 - rvqvae_loss: 301.2118\n",
            "Epoch 45/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 302.5219 - reconstruction_loss: 0.0547 - rvqvae_loss: 302.4673\n",
            "Epoch 46/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 300.0418 - reconstruction_loss: 0.0541 - rvqvae_loss: 299.9877\n",
            "Epoch 47/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 298.6837 - reconstruction_loss: 0.0537 - rvqvae_loss: 298.6299\n",
            "Epoch 48/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 300.2775 - reconstruction_loss: 0.0536 - rvqvae_loss: 300.2238\n",
            "Epoch 49/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 304.2102 - reconstruction_loss: 0.0534 - rvqvae_loss: 304.1567\n",
            "Epoch 50/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 304.0524 - reconstruction_loss: 0.0529 - rvqvae_loss: 303.9994\n"
          ]
        }
      ],
      "source": [
        "num_quant = 1\n",
        "vqvae_trainer = RVQVAETrainer(data_variance, latent_dim=16, num_embeddings=512, num_quantizers = num_quant)\n",
        "vqvae_trainer.compile(optimizer=keras.optimizers.Adam())\n",
        "history = vqvae_trainer.fit(x_train_scaled, epochs=50, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NaPvlpeUUh5"
      },
      "source": [
        "## Reconstruction results on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 388,
      "metadata": {
        "id": "-HsHZ60qUUh5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def show_subplot(original, reconstructed):\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(original.squeeze() + 0.5)\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(reconstructed.squeeze() + 0.5)\n",
        "    plt.title(\"Reconstructed\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "samples = 3\n",
        "trained_vqvae_model = vqvae_trainer.rvqvae\n",
        "idx = np.random.choice(len(x_test_scaled), 10000)\n",
        "test_images = x_test_scaled[idx]\n",
        "test_images_sub = test_images[:1000]\n",
        "reconstructions_test = trained_vqvae_model.predict(test_images_sub)\n",
        "\n",
        "#for test_image, reconstructed_image in zip(test_images_sub, reconstructions_test):\n",
        " #   show_subplot(test_image, reconstructed_image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9JBu8GgUUh5"
      },
      "source": [
        "## Visualizing the discrete codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(1, 28, 28, 1)"
            ]
          },
          "execution_count": 273,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Load the image in grayscale (0 means grayscale)\n",
        "image = cv2.imread(r'E:\\Second Term\\Gen AI\\Project\\mnist_random_image.png', cv2.IMREAD_GRAYSCALE)\n",
        "image = image/255 -0.5\n",
        "expanded_image = np.expand_dims(image, axis=0)  # Shape becomes (1, 28, 28)\n",
        "expanded_image = np.expand_dims(expanded_image, axis=-1)  # Shape becomes (1, 28, 28, 1)\n",
        "\n",
        "# Display the image using matplotlib\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()\n",
        "np.shape(expanded_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYwGaSXqUUh5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Error at quantization stage 1 (L2 norm): 2.193547248840332\n",
            "Error at quantization stage 2 (L2 norm): 2.135688543319702\n",
            "Error at quantization stage 3 (L2 norm): 2.0877902507781982\n",
            "Error at quantization stage 4 (L2 norm): 2.061457633972168\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the encoder and vector quantizer layers\n",
        "encoder = vqvae_trainer.rvqvae.get_layer(\"encoder\")\n",
        "quantizer = vqvae_trainer.rvqvae.get_layer(\"vector_quantizer\")\n",
        "\n",
        "\n",
        "num_random_images = 1\n",
        "random_indices = np.random.choice(test_images.shape[0], num_random_images, replace=False)\n",
        "\n",
        "#test_images_subset = test_images[random_indices]\n",
        "test_images_subset = test_images[:3]\n",
        "\n",
        "encoded_outputs = encoder.predict(test_images_subset)  \n",
        "batch_size, height, width, channels = encoded_outputs.shape\n",
        "flat_enc_outputs = encoded_outputs.reshape(batch_size * height * width, channels)\n",
        "\n",
        "all_quantized_outputs = []\n",
        "\n",
        "residual = flat_enc_outputs\n",
        "for i in range(quantizer.num_quantizers):\n",
        "    embedding_matrix = quantizer.embeddings[i] \n",
        "    \n",
        "    codebook_indices = quantizer.get_code_indices(residual, embedding_matrix)\n",
        "    \n",
        "    encodings = tf.one_hot(codebook_indices, quantizer.num_embeddings)\n",
        "    quantized = tf.matmul(encodings, embedding_matrix, transpose_b=True)\n",
        "    \n",
        "    all_quantized_outputs.append(quantized.numpy().reshape(batch_size, height, width, channels))\n",
        "\n",
        "    residual -= quantized\n",
        "    \n",
        "    error = tf.norm(residual, axis=-1)  \n",
        "    error_value = tf.reduce_mean(error).numpy()  \n",
        "    print(f\"Error at quantization stage {i + 1} (L2 norm): {error_value}\")\n",
        "\n",
        "\n",
        "# Visualize individual channels from the quantized output\n",
        "for i in range(len(test_images_subset)):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot the original image\n",
        "    plt.subplot(1, len(all_quantized_outputs) + 1, 1)\n",
        "    plt.imshow(test_images_subset[i].squeeze() + 0.5, cmap=\"gray\")\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Plot individual channels from the quantized output after each quantization stage\n",
        "    for j, quantized_output in enumerate(all_quantized_outputs):\n",
        "        plt.subplot(1, len(all_quantized_outputs) + 1, j + 2)\n",
        "        plt.imshow(quantized_output[i, :, :, 0], cmap=\"viridis\")  # Show the first channel\n",
        "        plt.title(f\"Quantized Stage {j + 1} \")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def get_quantized_token_indices(test_images, encoder, quantizer):\n",
        "\n",
        "  \n",
        "    encoded_outputs = encoder.predict(test_images)  \n",
        "    batch_size, height, width, channels = encoded_outputs.shape\n",
        "\n",
        "    # Flatten spatial dims\n",
        "    flat_enc_outputs = encoded_outputs.reshape(batch_size * height * width, channels)\n",
        "\n",
        "    # Collect codebook indices at each stage\n",
        "    all_indices = []\n",
        "\n",
        "    residual = flat_enc_outputs\n",
        "    for i in range(quantizer.num_quantizers):\n",
        "        embedding_matrix = quantizer.embeddings[i]\n",
        "        codebook_indices = quantizer.get_code_indices(residual, embedding_matrix)\n",
        "        all_indices.append(codebook_indices.numpy().reshape(batch_size, height * width))\n",
        "        \n",
        "        # Quantized vectors\n",
        "        encodings = tf.one_hot(codebook_indices, quantizer.num_embeddings)\n",
        "        quantized = tf.matmul(encodings, embedding_matrix, transpose_b=True)\n",
        "        \n",
        "        # Residual for next stage\n",
        "        residual -= quantized\n",
        "\n",
        "    quantized_tokens = np.stack(all_indices, axis=-1)  \n",
        "    return quantized_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "(10000, 49, 1)\n"
          ]
        }
      ],
      "source": [
        "encoder = vqvae_trainer.rvqvae.get_layer(\"encoder\")\n",
        "quantizer = vqvae_trainer.rvqvae.get_layer(\"vector_quantizer\")\n",
        "\n",
        "quantized_tokens = get_quantized_token_indices(test_images, encoder, quantizer)\n",
        "\n",
        "print(quantized_tokens.shape)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rq_transformer import RQTransformer  \n",
        "\n",
        "rq_transformer = RQTransformer(\n",
        "    num_tokens = quantizer.num_embeddings,  #Number of embdeddings in each quantizer\n",
        "    dim = 512,                              \n",
        "    max_spatial_seq_len = 49,              # matches 7x7 = 49 patches\n",
        "    depth_seq_len = 2,                     # number of quantizers\n",
        "    spatial_layers = 6,                    # number of transformer layers for spatial modeling\n",
        "    depth_layers = 4,                      # number of transformer layers for depth modeling\n",
        "    dim_head = 64,\n",
        "    heads = 8\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Loss: 0.7422\n",
            "Epoch 2 - Loss: 0.7089\n",
            "Epoch 3 - Loss: 0.7085\n",
            "Epoch 4 - Loss: 0.6432\n",
            "Epoch 5 - Loss: 0.6178\n",
            "Epoch 6 - Loss: 0.6644\n",
            "Epoch 7 - Loss: 0.6102\n",
            "Epoch 8 - Loss: 0.5818\n",
            "Epoch 9 - Loss: 0.5659\n",
            "Epoch 10 - Loss: 0.6051\n",
            "Epoch 11 - Loss: 0.6703\n",
            "Epoch 12 - Loss: 0.6566\n",
            "Epoch 13 - Loss: 0.6230\n",
            "Epoch 14 - Loss: 0.6129\n",
            "Epoch 15 - Loss: 0.5910\n",
            "Epoch 16 - Loss: 0.5555\n",
            "Epoch 17 - Loss: 0.5559\n",
            "Epoch 18 - Loss: 0.5243\n",
            "Epoch 19 - Loss: 0.5507\n",
            "Epoch 20 - Loss: 0.5421\n",
            "Epoch 21 - Loss: 0.5415\n",
            "Epoch 22 - Loss: 0.5336\n",
            "Epoch 23 - Loss: 0.6223\n",
            "Epoch 24 - Loss: 0.7171\n",
            "Epoch 25 - Loss: 0.7709\n",
            "Epoch 26 - Loss: 0.6926\n",
            "Epoch 27 - Loss: 0.7149\n",
            "Epoch 28 - Loss: 0.6216\n",
            "Epoch 29 - Loss: 0.6064\n",
            "Epoch 30 - Loss: 0.5986\n",
            "Epoch 31 - Loss: 0.5603\n",
            "Epoch 32 - Loss: 0.5384\n",
            "Epoch 33 - Loss: 0.5579\n",
            "Epoch 34 - Loss: 0.5219\n",
            "Epoch 35 - Loss: 0.5128\n",
            "Epoch 36 - Loss: 0.5242\n",
            "Epoch 37 - Loss: 0.5098\n",
            "Epoch 38 - Loss: 0.5420\n",
            "Epoch 39 - Loss: 0.5081\n",
            "Epoch 40 - Loss: 0.5290\n",
            "Epoch 41 - Loss: 0.5055\n",
            "Epoch 42 - Loss: 0.5077\n",
            "Epoch 43 - Loss: 0.4955\n",
            "Epoch 44 - Loss: 0.4957\n",
            "Epoch 45 - Loss: 0.5114\n",
            "Epoch 46 - Loss: 0.5152\n",
            "Epoch 47 - Loss: 0.4943\n",
            "Epoch 48 - Loss: 0.5175\n",
            "Epoch 49 - Loss: 0.5173\n",
            "Epoch 50 - Loss: 0.5118\n",
            "Epoch 51 - Loss: 0.4972\n",
            "Epoch 52 - Loss: 0.5017\n",
            "Epoch 53 - Loss: 0.5074\n",
            "Epoch 54 - Loss: 0.5245\n",
            "Epoch 55 - Loss: 0.4992\n",
            "Epoch 56 - Loss: 0.5035\n",
            "Epoch 57 - Loss: 0.5156\n",
            "Epoch 58 - Loss: 0.5255\n",
            "Epoch 59 - Loss: 0.5008\n",
            "Epoch 60 - Loss: 0.5202\n",
            "Epoch 61 - Loss: 0.5123\n",
            "Epoch 62 - Loss: 0.5089\n",
            "Epoch 63 - Loss: 0.4897\n",
            "Epoch 64 - Loss: 0.5031\n",
            "Epoch 65 - Loss: 0.5105\n",
            "Epoch 66 - Loss: 0.4917\n",
            "Epoch 67 - Loss: 0.4949\n",
            "Epoch 68 - Loss: 0.4994\n",
            "Epoch 69 - Loss: 0.5191\n",
            "Epoch 70 - Loss: 0.5310\n",
            "Epoch 71 - Loss: 0.4927\n",
            "Epoch 72 - Loss: 0.4855\n",
            "Epoch 73 - Loss: 0.5121\n",
            "Epoch 74 - Loss: 0.5084\n",
            "Epoch 75 - Loss: 0.5129\n",
            "Epoch 76 - Loss: 0.5049\n",
            "Epoch 77 - Loss: 0.5164\n",
            "Epoch 78 - Loss: 0.5167\n",
            "Epoch 79 - Loss: 0.4992\n",
            "Epoch 80 - Loss: 0.4876\n",
            "Epoch 81 - Loss: 0.4947\n",
            "Epoch 82 - Loss: 0.5076\n",
            "Epoch 83 - Loss: 0.5246\n",
            "Epoch 84 - Loss: 0.5128\n",
            "Epoch 85 - Loss: 0.4911\n",
            "Epoch 86 - Loss: 0.4913\n",
            "Epoch 87 - Loss: 0.4875\n",
            "Epoch 88 - Loss: 0.5273\n",
            "Epoch 89 - Loss: 0.4981\n",
            "Epoch 90 - Loss: 0.4981\n",
            "Epoch 91 - Loss: 0.4984\n",
            "Epoch 92 - Loss: 0.4904\n",
            "Epoch 93 - Loss: 0.4921\n",
            "Epoch 94 - Loss: 0.5175\n",
            "Epoch 95 - Loss: 0.4895\n",
            "Epoch 96 - Loss: 0.4891\n",
            "Epoch 97 - Loss: 0.4895\n",
            "Epoch 98 - Loss: 0.4911\n",
            "Epoch 99 - Loss: 0.4860\n",
            "Epoch 100 - Loss: 0.5048\n",
            "Epoch 101 - Loss: 0.4804\n",
            "Epoch 102 - Loss: 0.5163\n",
            "Epoch 103 - Loss: 0.4833\n",
            "Epoch 104 - Loss: 0.4865\n",
            "Epoch 105 - Loss: 0.4881\n",
            "Epoch 106 - Loss: 0.4987\n",
            "Epoch 107 - Loss: 0.5211\n",
            "Epoch 108 - Loss: 0.5072\n",
            "Epoch 109 - Loss: 0.5130\n",
            "Epoch 110 - Loss: 0.4894\n",
            "Epoch 111 - Loss: 0.4851\n",
            "Epoch 112 - Loss: 0.4847\n",
            "Epoch 113 - Loss: 0.4915\n",
            "Epoch 114 - Loss: 0.5048\n",
            "Epoch 115 - Loss: 0.5007\n",
            "Epoch 116 - Loss: 0.4944\n",
            "Epoch 117 - Loss: 0.4973\n",
            "Epoch 118 - Loss: 0.4837\n",
            "Epoch 119 - Loss: 0.5137\n",
            "Epoch 120 - Loss: 0.5017\n",
            "Epoch 121 - Loss: 0.5194\n",
            "Epoch 122 - Loss: 0.4864\n",
            "Epoch 123 - Loss: 0.4890\n",
            "Epoch 124 - Loss: 0.4992\n",
            "Epoch 125 - Loss: 0.4946\n",
            "Epoch 126 - Loss: 0.4860\n",
            "Epoch 127 - Loss: 0.5089\n",
            "Epoch 128 - Loss: 0.4947\n",
            "Epoch 129 - Loss: 0.5342\n",
            "Epoch 130 - Loss: 0.5005\n",
            "Epoch 131 - Loss: 0.4962\n",
            "Epoch 132 - Loss: 0.4801\n",
            "Epoch 133 - Loss: 0.4879\n",
            "Epoch 134 - Loss: 0.4856\n",
            "Epoch 135 - Loss: 0.4820\n",
            "Epoch 136 - Loss: 0.4845\n",
            "Epoch 137 - Loss: 0.4863\n",
            "Epoch 138 - Loss: 0.4877\n",
            "Epoch 139 - Loss: 0.5121\n",
            "Epoch 140 - Loss: 0.4983\n",
            "Epoch 141 - Loss: 0.4820\n",
            "Epoch 142 - Loss: 0.4856\n",
            "Epoch 143 - Loss: 0.4876\n",
            "Epoch 144 - Loss: 0.4816\n",
            "Epoch 145 - Loss: 0.4941\n",
            "Epoch 146 - Loss: 0.5317\n",
            "Epoch 147 - Loss: 0.4953\n",
            "Epoch 148 - Loss: 0.5124\n",
            "Epoch 149 - Loss: 0.5102\n",
            "Epoch 150 - Loss: 0.5121\n",
            "Epoch 151 - Loss: 0.4706\n",
            "Epoch 152 - Loss: 0.5328\n",
            "Epoch 153 - Loss: 0.4974\n",
            "Epoch 154 - Loss: 0.4748\n",
            "Epoch 155 - Loss: 0.5176\n",
            "Epoch 156 - Loss: 0.4875\n",
            "Epoch 157 - Loss: 0.4977\n",
            "Epoch 158 - Loss: 0.4884\n",
            "Epoch 159 - Loss: 0.5144\n",
            "Epoch 160 - Loss: 0.4854\n",
            "Epoch 161 - Loss: 0.4832\n",
            "Epoch 162 - Loss: 0.4998\n",
            "Epoch 163 - Loss: 0.4982\n",
            "Epoch 164 - Loss: 0.4882\n",
            "Epoch 165 - Loss: 0.4771\n",
            "Epoch 166 - Loss: 0.4814\n",
            "Epoch 167 - Loss: 0.4902\n",
            "Epoch 168 - Loss: 0.4841\n",
            "Epoch 169 - Loss: 0.5360\n",
            "Epoch 170 - Loss: 0.4925\n",
            "Epoch 171 - Loss: 0.4965\n",
            "Epoch 172 - Loss: 0.4906\n",
            "Epoch 173 - Loss: 0.4881\n",
            "Epoch 174 - Loss: 0.4767\n",
            "Epoch 175 - Loss: 0.4979\n",
            "Epoch 176 - Loss: 0.5115\n",
            "Epoch 177 - Loss: 0.5162\n",
            "Epoch 178 - Loss: 0.4777\n",
            "Epoch 179 - Loss: 0.4893\n",
            "Epoch 180 - Loss: 0.4887\n",
            "Epoch 181 - Loss: 0.4970\n",
            "Epoch 182 - Loss: 0.4868\n",
            "Epoch 183 - Loss: 0.4838\n",
            "Epoch 184 - Loss: 0.5044\n",
            "Epoch 185 - Loss: 0.5016\n",
            "Epoch 186 - Loss: 0.4783\n",
            "Epoch 187 - Loss: 0.4950\n",
            "Epoch 188 - Loss: 0.4912\n",
            "Epoch 189 - Loss: 0.4797\n",
            "Epoch 190 - Loss: 0.4770\n",
            "Epoch 191 - Loss: 0.4775\n",
            "Epoch 192 - Loss: 0.4790\n",
            "Epoch 193 - Loss: 0.4808\n",
            "Epoch 194 - Loss: 0.4963\n",
            "Epoch 195 - Loss: 0.4800\n",
            "Epoch 196 - Loss: 0.4771\n",
            "Epoch 197 - Loss: 0.5016\n",
            "Epoch 198 - Loss: 0.4901\n",
            "Epoch 199 - Loss: 0.4846\n",
            "Epoch 200 - Loss: 0.5152\n",
            "Epoch 201 - Loss: 0.4830\n",
            "Epoch 202 - Loss: 0.4859\n",
            "Epoch 203 - Loss: 0.4986\n",
            "Epoch 204 - Loss: 0.4839\n",
            "Epoch 205 - Loss: 0.4742\n",
            "Epoch 206 - Loss: 0.4715\n",
            "Epoch 207 - Loss: 0.4961\n",
            "Epoch 208 - Loss: 0.4892\n",
            "Epoch 209 - Loss: 0.4929\n",
            "Epoch 210 - Loss: 0.5020\n",
            "Epoch 211 - Loss: 0.4801\n",
            "Epoch 212 - Loss: 0.4883\n",
            "Epoch 213 - Loss: 0.4924\n",
            "Epoch 214 - Loss: 0.5017\n",
            "Epoch 215 - Loss: 0.4721\n",
            "Epoch 216 - Loss: 0.5072\n",
            "Epoch 217 - Loss: 0.4784\n",
            "Epoch 218 - Loss: 0.4942\n",
            "Epoch 219 - Loss: 0.4886\n",
            "Epoch 220 - Loss: 0.4747\n",
            "Epoch 221 - Loss: 0.4881\n",
            "Epoch 222 - Loss: 0.4762\n",
            "Epoch 223 - Loss: 0.4887\n",
            "Epoch 224 - Loss: 0.4956\n",
            "Epoch 225 - Loss: 0.4783\n",
            "Epoch 226 - Loss: 0.4786\n",
            "Epoch 227 - Loss: 0.4774\n",
            "Epoch 228 - Loss: 0.5143\n",
            "Epoch 229 - Loss: 0.4663\n",
            "Epoch 230 - Loss: 0.5009\n",
            "Epoch 231 - Loss: 0.4827\n",
            "Epoch 232 - Loss: 0.4951\n",
            "Epoch 233 - Loss: 0.4716\n",
            "Epoch 234 - Loss: 0.4758\n",
            "Epoch 235 - Loss: 0.4926\n",
            "Epoch 236 - Loss: 0.5200\n",
            "Epoch 237 - Loss: 0.4872\n",
            "Epoch 238 - Loss: 0.5163\n",
            "Epoch 239 - Loss: 0.5065\n",
            "Epoch 240 - Loss: 0.4999\n",
            "Epoch 241 - Loss: 0.4950\n",
            "Epoch 242 - Loss: 0.4963\n",
            "Epoch 243 - Loss: 0.5121\n",
            "Epoch 244 - Loss: 0.4916\n",
            "Epoch 245 - Loss: 0.4999\n",
            "Epoch 246 - Loss: 0.4895\n",
            "Epoch 247 - Loss: 0.5102\n",
            "Epoch 248 - Loss: 0.4912\n",
            "Epoch 249 - Loss: 0.4856\n",
            "Epoch 250 - Loss: 0.5156\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "tokens = torch.tensor(quantized_tokens[:1000], dtype=torch.long)\n",
        "dataset = TensorDataset(tokens)\n",
        "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "optimizer = torch.optim.Adam(rq_transformer.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(100):\n",
        "    total_loss = 0\n",
        "    for (x,) in loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = rq_transformer(x, return_loss=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} - Loss: {total_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ##  Generate tokens from RQ transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "samples = []\n",
        "\n",
        "for i in range(batch_size):\n",
        "    sample = rq_transformer.generate() \n",
        "    samples.append(sample.squeeze(0).cpu().numpy())  \n",
        "    print(i)\n",
        "generated_tokens = np.stack(samples, axis=0) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transformer_tokens_to_latents_batch(generated_tokens, quantizer):\n",
        "    \"\"\"\n",
        "    Converts RQTransformer-generated token indices (B, 49, 3) into quantized latent tensor (B, 7, 7, latent_dim)\n",
        "    \"\"\"\n",
        "    batch_size, seq_len, num_quantizers = generated_tokens.shape\n",
        "    h = w = int(seq_len ** 0.5)\n",
        "    latent_dim = quantizer.embedding_dim\n",
        "\n",
        "    quantized_latents = np.zeros((batch_size, seq_len, latent_dim), dtype=np.float32)\n",
        "\n",
        "    for i in range(num_quantizers):\n",
        "        codebook = quantizer.embeddings[i].numpy().T  \n",
        "        indices = generated_tokens[:, :, i]  \n",
        "        embeddings = codebook[indices]  \n",
        "        quantized_latents += embeddings\n",
        "\n",
        "    quantized_latents = quantized_latents.reshape(batch_size, h, w, latent_dim)\n",
        "    return quantized_latents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "decoder_input = transformer_tokens_to_latents_batch(generated_tok, quantizer)  # (B, 7, 7, 4)\n",
        "decoder_input_tensor = tf.convert_to_tensor(decoder_input, dtype=tf.float32)\n",
        "\n",
        "# Step 2: Decode\n",
        "decoder = vqvae_trainer.rvqvae.get_layer(\"decoder\")\n",
        "generated_images = decoder(decoder_input_tensor)  # (B, 28, 28, 1)\n",
        "\n",
        "# Step 3: Visualize the batch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(generated_images):\n",
        "    plt.subplot(1, generated_images, i+1)\n",
        "    plt.imshow(generated_images[i].numpy().squeeze(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "real_images = tf.convert_to_tensor(x_test_scaled[:1000], dtype=tf.float32)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
