{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Okl2JnUUhr"
      },
      "source": [
        "# Vector-Quantized Variational Autoencoders\n",
        "\n",
        "**Author:** [Sayak Paul](https://twitter.com/RisingSayak)<br>\n",
        "**Date created:** 2021/07/21<br>\n",
        "**Last modified:** 2022/06/27<br>\n",
        "**Description:** Training a VQ-VAE for image reconstruction and codebook sampling for generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv71MA0DUUhv"
      },
      "source": [
        "In this example, we develop a Vector Quantized Variational Autoencoder (VQ-VAE).\n",
        "VQ-VAE was proposed in\n",
        "[Neural Discrete Representation Learning](https://arxiv.org/abs/1711.00937)\n",
        "by van der Oord et al. In standard VAEs, the latent space is continuous and is sampled\n",
        "from a Gaussian distribution. It is generally harder to learn such a continuous\n",
        "distribution via gradient descent. VQ-VAEs, on the other hand,\n",
        "operate on a discrete latent space, making the optimization problem simpler. It does so\n",
        "by maintaining a discrete *codebook*. The codebook is developed by\n",
        "discretizing the distance between continuous embeddings and the encoded\n",
        "outputs. These discrete code words are then fed to the decoder, which is trained\n",
        "to generate reconstructed samples.\n",
        "\n",
        "For an overview of VQ-VAEs, please refer to the original paper and\n",
        "[this video explanation](https://www.youtube.com/watch?v=VZFVUrYcig0).\n",
        "If you need a refresher on VAEs, you can refer to\n",
        "[this book chapter](https://livebook.manning.com/book/deep-learning-with-python-second-edition/chapter-12/).\n",
        "VQ-VAEs are one of the main recipes behind [DALL-E](https://openai.com/blog/dall-e/)\n",
        "and the idea of a codebook is used in [VQ-GANs](https://arxiv.org/abs/2012.09841).\n",
        "\n",
        "This example uses implementation details from the\n",
        "[official VQ-VAE tutorial](https://github.com/deepmind/sonnet/blob/master/sonnet/examples/vqvae_example.ipynb)\n",
        "from DeepMind.\n",
        "## Requirements\n",
        "To run this example, you will need TensorFlow 2.5 or higher, as well as\n",
        "TensorFlow Probability, which can be installed using the command below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-3ZUN7rUUhy"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-hu-GqEYUUhy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From e:\\Second Term\\Gen AI\\Project\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From e:\\Second Term\\Gen AI\\Project\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
            "\n",
            "WARNING:tensorflow:From e:\\Second Term\\Gen AI\\Project\\venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-probability\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLkzFH5UUUhy"
      },
      "source": [
        "## Residual VectorQuantizer layer\n",
        "\n",
        "First, we implement a custom layer for the vector quantizer, which is the layer in between\n",
        "the encoder and decoder. Consider an output from the encoder, with shape `(batch_size, height, width,\n",
        "num_filters)`. The vector quantizer will first flatten this output, only keeping the\n",
        "`num_filters` dimension intact. So, the shape would become `(batch_size * height * width,\n",
        "num_filters)`. The rationale behind this is to treat the total number of filters as the size for\n",
        "the latent embeddings.\n",
        "\n",
        "An embedding table is then initialized to learn a codebook. We measure the L2-normalized\n",
        "distance between the flattened encoder outputs and code words of this codebook. We take the\n",
        "code that yields the minimum distance, and we apply one-hot encoding to achieve quantization.\n",
        "This way, the code yielding the minimum distance to the corresponding encoder output is\n",
        "mapped as one and the remaining codes are mapped as zeros.\n",
        "\n",
        "Since the quantization process is not differentiable, we apply a\n",
        "[straight-through estimator](https://www.hassanaskary.com/python/pytorch/deep%20learning/2020/09/19/intuitive-explanation-of-straight-through-estimators.html)\n",
        "in between the decoder and the encoder, so that the decoder gradients are directly propagated\n",
        "to the encoder. As the encoder and decoder share the same channel space, the decoder gradients are\n",
        "still meaningful to the encoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4Q3wR9iUUh0"
      },
      "source": [
        "**A note on straight-through estimation**:\n",
        "\n",
        "This line of code does the straight-through estimation part: `quantized = x +\n",
        "tf.stop_gradient(quantized - x)`. During backpropagation, `(quantized - x)` won't be\n",
        "included in the computation graph and the gradients obtained for `quantized`\n",
        "will be copied for `inputs`. Thanks to [this video](https://youtu.be/VZFVUrYcig0?t=1393)\n",
        "for helping me understand this technique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Residual "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualVectorQuantizer(layers.Layer):\n",
        "    def __init__(self, num_embeddings, embedding_dim, num_quantizers, beta=0.25, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.num_quantizers = num_quantizers  # Number of residual quantization stages\n",
        "        self.beta = beta\n",
        "\n",
        "        # Create multiple embedding matrices (one per quantization stage)\n",
        "        w_init =  tf.keras.initializers.RandomUniform()\n",
        "        self.embeddings = [\n",
        "            tf.Variable(\n",
        "                initial_value=w_init(\n",
        "                    shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"\n",
        "                ),\n",
        "                trainable=True,\n",
        "                name=f\"embeddings_vqvae_{i}\",\n",
        "            )\n",
        "            for i in range(self.num_quantizers)\n",
        "        ]\n",
        "\n",
        "    def call(self, x):\n",
        "        shape = tf.shape(x)  # Get dynamic shape\n",
        "        batch_size, height, width, channels = shape[0], shape[1], shape[2], shape[3]\n",
        "        flattened = tf.reshape(x, [batch_size * height * width, channels])\n",
        "\n",
        "        residual = flattened\n",
        "        quantized_output = tf.zeros_like(flattened)\n",
        "        total_commitment_loss = 0\n",
        "        total_codebook_loss = 0\n",
        "\n",
        "\n",
        "        for i in range(self.num_quantizers):\n",
        "            # Quantization for the current stage\n",
        "            encoding_indices = self.get_code_indices(residual, self.embeddings[i])\n",
        "            encodings = tf.one_hot(encoding_indices, self.num_embeddings)\n",
        "            quantized = tf.matmul(encodings, self.embeddings[i], transpose_b=True)\n",
        "\n",
        "            \n",
        "            # Compute loss\n",
        "            codebook_loss = tf.reduce_mean((tf.stop_gradient(residual) - quantized) ** 2)\n",
        "            commitment_loss = tf.reduce_mean((residual - tf.stop_gradient(quantized)) ** 2)\n",
        "            total_commitment_loss += commitment_loss\n",
        "            total_codebook_loss += codebook_loss\n",
        "\n",
        "            \n",
        "            # Compute residual for the next stage\n",
        "            residual -= quantized\n",
        "            quantized_output += quantized\n",
        "    \n",
        "       # total_codebook_loss1 = tf.reduce_mean((tf.stop_gradient(flattened) - quantized_output) ** 2)\n",
        "        #total_commitment_loss1 = tf.reduce_mean((flattened - tf.stop_gradient(quantized_output)) ** 2)\n",
        "        total_loss = self.beta * total_commitment_loss + total_codebook_loss\n",
        "        # Add total loss\n",
        "        self.add_loss(total_loss)\n",
        "\n",
        "        # Reshape back to (batch, height, width, channels)\n",
        "        quantized_output = tf.reshape(quantized_output, [batch_size, height, width, channels])\n",
        "\n",
        "        # Straight-through estimator\n",
        "        quantized_output = x + tf.stop_gradient(quantized_output - x)\n",
        "        return quantized_output\n",
        "\n",
        "    def get_code_indices(self, inputs, embedding_matrix):\n",
        "        # Calculate L2-normalized distance between inputs and codebook vectors\n",
        "        similarity = tf.matmul(inputs, embedding_matrix)\n",
        "        distances = (\n",
        "            tf.reduce_sum(inputs ** 2, axis=1, keepdims=True)\n",
        "            + tf.reduce_sum(embedding_matrix ** 2, axis=0)\n",
        "            - 2 * similarity\n",
        "        )\n",
        "\n",
        "        # Get the index of the nearest codebook vector\n",
        "        encoding_indices = tf.argmin(distances, axis=1)\n",
        "        return encoding_indices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-aVrzU_UUh1"
      },
      "source": [
        "## Encoder and decoder\n",
        "\n",
        "Now for the encoder and the decoder for the VQ-VAE. We will keep them small so\n",
        "that their capacity is a good fit for the MNIST dataset. The implementation of the encoder and\n",
        "come from\n",
        "[this example](https://keras.io/examples/generative/vae).\n",
        "\n",
        "Note that activations _other than ReLU_ may not work for the encoder and decoder layers in the\n",
        "quantization architecture: Leaky ReLU activated layers, for example, have proven difficult to\n",
        "train, resulting in intermittent loss spikes that the model has trouble recovering from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JujsUdT2UUh1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_encoder(latent_dim=16):\n",
        "    encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
        "    x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
        "        encoder_inputs\n",
        "    )\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    encoder_outputs = layers.Conv2D(latent_dim, 1, padding=\"same\")(x)\n",
        "    return keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n",
        "\n",
        "\n",
        "def get_decoder(latent_dim=16):\n",
        "    latent_inputs = keras.Input(shape=get_encoder(latent_dim).output.shape[1:])\n",
        "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
        "        latent_inputs\n",
        "    )\n",
        "    x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    decoder_outputs = layers.Conv2DTranspose(1, 3, padding=\"same\")(x)\n",
        "    return keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining RQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"rvq_vae\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"rvq_vae\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,076</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ vector_quantizer                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualVectorQuantizer</span>)       │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,121</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │        \u001b[38;5;34m19,076\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ vector_quantizer                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mResidualVectorQuantizer\u001b[0m)       │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │        \u001b[38;5;34m21,121\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,197</span> (157.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,197\u001b[0m (157.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,197</span> (157.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,197\u001b[0m (157.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "def get_vqvae(latent_dim=4, num_embeddings=64,num_quantizers =2):\n",
        "    rvq_layer = ResidualVectorQuantizer(num_embeddings, latent_dim,num_quantizers, name=\"vector_quantizer\")\n",
        "    encoder = get_encoder(latent_dim)\n",
        "    decoder = get_decoder(latent_dim)\n",
        "    inputs = keras.Input(shape=(28, 28, 1))\n",
        "    encoder_outputs = encoder(inputs)\n",
        "    quantized_latents = rvq_layer(encoder_outputs)\n",
        "    reconstructions = decoder(quantized_latents)\n",
        "    return keras.Model(inputs, reconstructions, name=\"rvq_vae\")\n",
        "\n",
        "get_vqvae().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwzLMWy6UUh3"
      },
      "source": [
        "## Wrapping up the training loop inside `RVQVAETrainer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QbfBDo8iUUh3"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RVQVAETrainer(keras.models.Model):\n",
        "    def __init__(self, train_variance, latent_dim=32, num_embeddings=128, num_quantizers = 2,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.train_variance = train_variance\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.num_quantizers = num_quantizers\n",
        "\n",
        "        self.rvqvae = get_vqvae(self.latent_dim, self.num_embeddings, self.num_quantizers)\n",
        "\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.rvq_loss_tracker = keras.metrics.Mean(name=\"rvq_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.rvq_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, x):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Outputs from the VQ-VAE.\n",
        "            reconstructions = self.rvqvae(x)\n",
        "\n",
        "            # Calculate the losses.\n",
        "            reconstruction_loss = (\n",
        "                tf.reduce_mean((x - reconstructions) ** 2) / self.train_variance\n",
        "            )\n",
        "            total_loss = reconstruction_loss + sum(self.rvqvae.losses)\n",
        "\n",
        "        # Backpropagation.\n",
        "        grads = tape.gradient(total_loss, self.rvqvae.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.rvqvae.trainable_variables))\n",
        "\n",
        "        # Loss tracking.\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.rvq_loss_tracker.update_state(sum(self.rvqvae.losses))\n",
        "\n",
        "        # Log results.\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"rvqvae_loss\": self.rvq_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5ljEADUUh4"
      },
      "source": [
        "## Load and preprocess the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "execution_count": 251,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shape(x_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST-R9nMNUUh4",
        "outputId": "bc130232-e750-4370-c910-7e9b9848418d"
      },
      "outputs": [],
      "source": [
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "x_train_scaled = (x_train / 255.0) - 0.5\n",
        "x_test_scaled = (x_test / 255.0) - 0.5\n",
        "\n",
        "data_variance = np.var(x_train / 255.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C2aF4jXUUh4"
      },
      "source": [
        "## Train the VQ-VAE model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5on6YX9UUh4",
        "outputId": "70b0de92-1b0b-4274-e3fb-fa90c602f212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - loss: 1.6984 - reconstruction_loss: 0.5301 - rvqvae_loss: 1.1683\n",
            "Epoch 2/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 75ms/step - loss: 3.3665 - reconstruction_loss: 0.0689 - rvqvae_loss: 3.2976\n",
            "Epoch 3/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 85ms/step - loss: 3.2962 - reconstruction_loss: 0.0567 - rvqvae_loss: 3.2395\n",
            "Epoch 4/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 60ms/step - loss: 3.3871 - reconstruction_loss: 0.0527 - rvqvae_loss: 3.3343\n",
            "Epoch 5/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - loss: 3.4385 - reconstruction_loss: 0.0505 - rvqvae_loss: 3.3880\n",
            "Epoch 6/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - loss: 3.6895 - reconstruction_loss: 0.0494 - rvqvae_loss: 3.6402\n",
            "Epoch 7/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - loss: 3.9304 - reconstruction_loss: 0.0484 - rvqvae_loss: 3.8820\n",
            "Epoch 8/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - loss: 4.0360 - reconstruction_loss: 0.0475 - rvqvae_loss: 3.9885\n",
            "Epoch 9/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - loss: 4.1257 - reconstruction_loss: 0.0465 - rvqvae_loss: 4.0792\n",
            "Epoch 10/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - loss: 4.2020 - reconstruction_loss: 0.0458 - rvqvae_loss: 4.1562\n",
            "Epoch 11/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - loss: 4.2365 - reconstruction_loss: 0.0450 - rvqvae_loss: 4.1915\n",
            "Epoch 12/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - loss: 4.1704 - reconstruction_loss: 0.0443 - rvqvae_loss: 4.1262\n",
            "Epoch 13/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - loss: 4.3456 - reconstruction_loss: 0.0442 - rvqvae_loss: 4.3014\n",
            "Epoch 14/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 83ms/step - loss: 4.5307 - reconstruction_loss: 0.0441 - rvqvae_loss: 4.4866\n",
            "Epoch 15/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - loss: 4.6355 - reconstruction_loss: 0.0439 - rvqvae_loss: 4.5916\n",
            "Epoch 16/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 85ms/step - loss: 4.7462 - reconstruction_loss: 0.0440 - rvqvae_loss: 4.7022\n",
            "Epoch 17/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - loss: 4.7990 - reconstruction_loss: 0.0438 - rvqvae_loss: 4.7552\n",
            "Epoch 18/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 95ms/step - loss: 4.8453 - reconstruction_loss: 0.0435 - rvqvae_loss: 4.8018\n",
            "Epoch 19/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 79ms/step - loss: 4.8902 - reconstruction_loss: 0.0433 - rvqvae_loss: 4.8468\n",
            "Epoch 20/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 70ms/step - loss: 5.0462 - reconstruction_loss: 0.0435 - rvqvae_loss: 5.0027\n",
            "Epoch 21/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 62ms/step - loss: 5.1173 - reconstruction_loss: 0.0431 - rvqvae_loss: 5.0742\n",
            "Epoch 22/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 61ms/step - loss: 5.1981 - reconstruction_loss: 0.0431 - rvqvae_loss: 5.1550\n",
            "Epoch 23/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 75ms/step - loss: 5.1491 - reconstruction_loss: 0.0427 - rvqvae_loss: 5.1065\n",
            "Epoch 24/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 71ms/step - loss: 5.1225 - reconstruction_loss: 0.0424 - rvqvae_loss: 5.0801\n",
            "Epoch 25/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 64ms/step - loss: 5.0831 - reconstruction_loss: 0.0421 - rvqvae_loss: 5.0410\n",
            "Epoch 26/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 78ms/step - loss: 5.0481 - reconstruction_loss: 0.0419 - rvqvae_loss: 5.0062\n",
            "Epoch 27/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - loss: 5.0808 - reconstruction_loss: 0.0416 - rvqvae_loss: 5.0391\n",
            "Epoch 28/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 75ms/step - loss: 5.1221 - reconstruction_loss: 0.0416 - rvqvae_loss: 5.0805\n",
            "Epoch 29/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 77ms/step - loss: 5.2286 - reconstruction_loss: 0.0415 - rvqvae_loss: 5.1871\n",
            "Epoch 30/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - loss: 5.2111 - reconstruction_loss: 0.0409 - rvqvae_loss: 5.1702\n",
            "Epoch 31/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 80ms/step - loss: 5.2931 - reconstruction_loss: 0.0410 - rvqvae_loss: 5.2521\n",
            "Epoch 32/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - loss: 5.3459 - reconstruction_loss: 0.0408 - rvqvae_loss: 5.3051\n",
            "Epoch 33/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 65ms/step - loss: 5.3682 - reconstruction_loss: 0.0405 - rvqvae_loss: 5.3277\n",
            "Epoch 34/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 64ms/step - loss: 5.5475 - reconstruction_loss: 0.0405 - rvqvae_loss: 5.5070\n",
            "Epoch 35/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 67ms/step - loss: 5.5766 - reconstruction_loss: 0.0404 - rvqvae_loss: 5.5362\n",
            "Epoch 36/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 67ms/step - loss: 5.7713 - reconstruction_loss: 0.0406 - rvqvae_loss: 5.7307\n",
            "Epoch 37/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - loss: 5.7822 - reconstruction_loss: 0.0405 - rvqvae_loss: 5.7417\n",
            "Epoch 38/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - loss: 5.8481 - reconstruction_loss: 0.0405 - rvqvae_loss: 5.8075\n",
            "Epoch 39/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 78ms/step - loss: 5.8603 - reconstruction_loss: 0.0406 - rvqvae_loss: 5.8197\n",
            "Epoch 40/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 78ms/step - loss: 5.8134 - reconstruction_loss: 0.0404 - rvqvae_loss: 5.7730\n",
            "Epoch 41/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - loss: 5.8998 - reconstruction_loss: 0.0407 - rvqvae_loss: 5.8591\n",
            "Epoch 42/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - loss: 5.8790 - reconstruction_loss: 0.0404 - rvqvae_loss: 5.8385\n",
            "Epoch 43/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 5.8523 - reconstruction_loss: 0.0402 - rvqvae_loss: 5.8122\n",
            "Epoch 44/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - loss: 5.7646 - reconstruction_loss: 0.0402 - rvqvae_loss: 5.7245\n",
            "Epoch 45/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 62ms/step - loss: 5.7540 - reconstruction_loss: 0.0399 - rvqvae_loss: 5.7141\n",
            "Epoch 46/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 62ms/step - loss: 5.8229 - reconstruction_loss: 0.0399 - rvqvae_loss: 5.7829\n",
            "Epoch 47/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 61ms/step - loss: 5.7210 - reconstruction_loss: 0.0396 - rvqvae_loss: 5.6814\n",
            "Epoch 48/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 60ms/step - loss: 5.7727 - reconstruction_loss: 0.0396 - rvqvae_loss: 5.7331\n",
            "Epoch 49/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 60ms/step - loss: 5.8332 - reconstruction_loss: 0.0396 - rvqvae_loss: 5.7936\n",
            "Epoch 50/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 60ms/step - loss: 5.8865 - reconstruction_loss: 0.0396 - rvqvae_loss: 5.8469\n"
          ]
        }
      ],
      "source": [
        "num_quant = 4\n",
        "vqvae_trainer = RVQVAETrainer(data_variance, latent_dim=16, num_embeddings=256, num_quantizers = num_quant)\n",
        "vqvae_trainer.compile(optimizer=keras.optimizers.Adam())\n",
        "history = vqvae_trainer.fit(x_train_scaled, epochs=50, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NaPvlpeUUh5"
      },
      "source": [
        "## Reconstruction results on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "id": "-HsHZ60qUUh5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def show_subplot(original, reconstructed):\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(original.squeeze() + 0.5)\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(reconstructed.squeeze() + 0.5)\n",
        "    plt.title(\"Reconstructed\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "samples = 3\n",
        "trained_vqvae_model = vqvae_trainer.rvqvae\n",
        "idx = np.random.choice(len(x_test_scaled), 10000)\n",
        "test_images = x_test_scaled[idx]\n",
        "test_images_sub = test_images[:1000]\n",
        "reconstructions_test = trained_vqvae_model.predict(test_images_sub)\n",
        "\n",
        "#for test_image, reconstructed_image in zip(test_images_sub, reconstructions_test):\n",
        " #   show_subplot(test_image, reconstructed_image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh3F-yIwUUh5"
      },
      "source": [
        "These results look decent. You are encouraged to play with different hyperparameters\n",
        "(especially the number of embeddings and the dimensions of the embeddings) and observe how\n",
        "they affect the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9JBu8GgUUh5"
      },
      "source": [
        "## Visualizing the discrete codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(1, 28, 28, 1)"
            ]
          },
          "execution_count": 273,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Load the image in grayscale (0 means grayscale)\n",
        "image = cv2.imread(r'E:\\Second Term\\Gen AI\\Project\\mnist_random_image.png', cv2.IMREAD_GRAYSCALE)\n",
        "image = image/255 -0.5\n",
        "expanded_image = np.expand_dims(image, axis=0)  # Shape becomes (1, 28, 28)\n",
        "expanded_image = np.expand_dims(expanded_image, axis=-1)  # Shape becomes (1, 28, 28, 1)\n",
        "\n",
        "# Display the image using matplotlib\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()\n",
        "np.shape(expanded_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "OYwGaSXqUUh5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Error at quantization stage 1 (L2 norm): 2.193547248840332\n",
            "Error at quantization stage 2 (L2 norm): 2.135688543319702\n",
            "Error at quantization stage 3 (L2 norm): 2.0877902507781982\n",
            "Error at quantization stage 4 (L2 norm): 2.061457633972168\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the encoder and vector quantizer layers\n",
        "encoder = vqvae_trainer.rvqvae.get_layer(\"encoder\")\n",
        "quantizer = vqvae_trainer.rvqvae.get_layer(\"vector_quantizer\")\n",
        "\n",
        "\n",
        "num_random_images = 1\n",
        "random_indices = np.random.choice(test_images.shape[0], num_random_images, replace=False)\n",
        "\n",
        "#test_images_subset = test_images[random_indices]\n",
        "test_images_subset = test_images[:3]\n",
        "\n",
        "encoded_outputs = encoder.predict(test_images_subset)  # Shape: (batch, height, width, channels)\n",
        "\n",
        "# Reshape for quantization (flatten spatial dimensions)\n",
        "batch_size, height, width, channels = encoded_outputs.shape\n",
        "flat_enc_outputs = encoded_outputs.reshape(batch_size * height * width, channels)\n",
        "\n",
        "# Initialize a list to store the quantized outputs after each stage\n",
        "all_quantized_outputs = []\n",
        "\n",
        "# Loop over each quantization stage\n",
        "residual = flat_enc_outputs\n",
        "for i in range(quantizer.num_quantizers):\n",
        "    embedding_matrix = quantizer.embeddings[i]  # Get the embedding matrix for this stage\n",
        "    \n",
        "    # Get the quantized indices for the current stage\n",
        "    codebook_indices = quantizer.get_code_indices(residual, embedding_matrix)\n",
        "    \n",
        "    # Compute the quantized output for the current stage\n",
        "    encodings = tf.one_hot(codebook_indices, quantizer.num_embeddings)\n",
        "    quantized = tf.matmul(encodings, embedding_matrix, transpose_b=True)\n",
        "    \n",
        "    # Store the quantized output after this stage\n",
        "    all_quantized_outputs.append(quantized.numpy().reshape(batch_size, height, width, channels))\n",
        "\n",
        "    # Compute the residual for the next stage\n",
        "    residual -= quantized\n",
        "    \n",
        "    # Compute the L2 norm error between the encoder output and the quantized output\n",
        "    error = tf.norm(residual, axis=-1)  # L2 norm error across channels\n",
        "    error_value = tf.reduce_mean(error).numpy()  # Take the average error for this stage\n",
        "    print(f\"Error at quantization stage {i + 1} (L2 norm): {error_value}\")\n",
        "\n",
        "\n",
        "# Visualize individual channels from the quantized output\n",
        "for i in range(len(test_images_subset)):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot the original image\n",
        "    plt.subplot(1, len(all_quantized_outputs) + 1, 1)\n",
        "    plt.imshow(test_images_subset[i].squeeze() + 0.5, cmap=\"gray\")\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Plot individual channels from the quantized output after each quantization stage\n",
        "    for j, quantized_output in enumerate(all_quantized_outputs):\n",
        "        plt.subplot(1, len(all_quantized_outputs) + 1, j + 2)\n",
        "        plt.imshow(quantized_output[i, :, :, 0], cmap=\"viridis\")  # Show the first channel\n",
        "        plt.title(f\"Quantized Stage {j + 1} \")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def get_quantized_token_indices(test_images, encoder, quantizer):\n",
        "    \"\"\"\n",
        "    Given test images and a trained encoder + residual vector quantizer,\n",
        "    returns quantized token indices in shape (batch, spatial_seq_len, depth_seq_len)\n",
        "    for use with RQTransformer.\n",
        "    \"\"\"\n",
        "    # Encode the images\n",
        "    encoded_outputs = encoder.predict(test_images)  # (B, H, W, C)\n",
        "    batch_size, height, width, channels = encoded_outputs.shape\n",
        "\n",
        "    # Flatten spatial dims\n",
        "    flat_enc_outputs = encoded_outputs.reshape(batch_size * height * width, channels)\n",
        "\n",
        "    # Collect codebook indices at each stage\n",
        "    all_indices = []\n",
        "\n",
        "    residual = flat_enc_outputs\n",
        "    for i in range(quantizer.num_quantizers):\n",
        "        embedding_matrix = quantizer.embeddings[i]\n",
        "        codebook_indices = quantizer.get_code_indices(residual, embedding_matrix)\n",
        "        all_indices.append(codebook_indices.numpy().reshape(batch_size, height * width))\n",
        "        \n",
        "        # Quantized vectors\n",
        "        encodings = tf.one_hot(codebook_indices, quantizer.num_embeddings)\n",
        "        quantized = tf.matmul(encodings, embedding_matrix, transpose_b=True)\n",
        "        \n",
        "        # Residual for next stage\n",
        "        residual -= quantized\n",
        "\n",
        "    # Stack into shape (batch, spatial_seq_len, depth_seq_len)\n",
        "    quantized_tokens = np.stack(all_indices, axis=-1)  # (B, H*W, depth_len)\n",
        "    return quantized_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "(10000, 49, 4)\n"
          ]
        }
      ],
      "source": [
        "encoder = vqvae_trainer.rvqvae.get_layer(\"encoder\")\n",
        "quantizer = vqvae_trainer.rvqvae.get_layer(\"vector_quantizer\")\n",
        "\n",
        "quantized_tokens = get_quantized_token_indices(test_images, encoder, quantizer)\n",
        "\n",
        "# Check shape\n",
        "print(quantized_tokens.shape)  # Should be (B, spatial_seq_len=H*W, depth_seq_len=num_quantizers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rq_transformer import RQTransformer  # assuming you're using lucidrains' library\n",
        "\n",
        "rq_transformer = RQTransformer(\n",
        "    num_tokens = quantizer.num_embeddings,  # should match the number of embeddings per quantizer\n",
        "    dim = 512,                              # or any model dimension you choose\n",
        "    max_spatial_seq_len = 49,              # matches 7x7 = 49 patches\n",
        "    depth_seq_len = 4,                     # number of quantizers\n",
        "    spatial_layers = 6,                    # number of transformer layers for spatial modeling\n",
        "    depth_layers = 4,                      # number of transformer layers for depth modeling\n",
        "    dim_head = 64,\n",
        "    heads = 8\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded shape: (10000, 49, 4)\n"
          ]
        }
      ],
      "source": [
        "np.shape(quantized_tokens)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Save to .npy file\n",
        "np.save(\"generated_latents_49x4.npy\", quantized_tokens)\n",
        "\n",
        "# To verify:\n",
        "loaded = np.load(\"generated_latents_49x4.npy\")\n",
        "print(\"Loaded shape:\", loaded.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Loss: 0.7422\n",
            "Epoch 2 - Loss: 0.7089\n",
            "Epoch 3 - Loss: 0.7085\n",
            "Epoch 4 - Loss: 0.6432\n",
            "Epoch 5 - Loss: 0.6178\n",
            "Epoch 6 - Loss: 0.6644\n",
            "Epoch 7 - Loss: 0.6102\n",
            "Epoch 8 - Loss: 0.5818\n",
            "Epoch 9 - Loss: 0.5659\n",
            "Epoch 10 - Loss: 0.6051\n",
            "Epoch 11 - Loss: 0.6703\n",
            "Epoch 12 - Loss: 0.6566\n",
            "Epoch 13 - Loss: 0.6230\n",
            "Epoch 14 - Loss: 0.6129\n",
            "Epoch 15 - Loss: 0.5910\n",
            "Epoch 16 - Loss: 0.5555\n",
            "Epoch 17 - Loss: 0.5559\n",
            "Epoch 18 - Loss: 0.5243\n",
            "Epoch 19 - Loss: 0.5507\n",
            "Epoch 20 - Loss: 0.5421\n",
            "Epoch 21 - Loss: 0.5415\n",
            "Epoch 22 - Loss: 0.5336\n",
            "Epoch 23 - Loss: 0.6223\n",
            "Epoch 24 - Loss: 0.7171\n",
            "Epoch 25 - Loss: 0.7709\n",
            "Epoch 26 - Loss: 0.6926\n",
            "Epoch 27 - Loss: 0.7149\n",
            "Epoch 28 - Loss: 0.6216\n",
            "Epoch 29 - Loss: 0.6064\n",
            "Epoch 30 - Loss: 0.5986\n",
            "Epoch 31 - Loss: 0.5603\n",
            "Epoch 32 - Loss: 0.5384\n",
            "Epoch 33 - Loss: 0.5579\n",
            "Epoch 34 - Loss: 0.5219\n",
            "Epoch 35 - Loss: 0.5128\n",
            "Epoch 36 - Loss: 0.5242\n",
            "Epoch 37 - Loss: 0.5098\n",
            "Epoch 38 - Loss: 0.5420\n",
            "Epoch 39 - Loss: 0.5081\n",
            "Epoch 40 - Loss: 0.5290\n",
            "Epoch 41 - Loss: 0.5055\n",
            "Epoch 42 - Loss: 0.5077\n",
            "Epoch 43 - Loss: 0.4955\n",
            "Epoch 44 - Loss: 0.4957\n",
            "Epoch 45 - Loss: 0.5114\n",
            "Epoch 46 - Loss: 0.5152\n",
            "Epoch 47 - Loss: 0.4943\n",
            "Epoch 48 - Loss: 0.5175\n",
            "Epoch 49 - Loss: 0.5173\n",
            "Epoch 50 - Loss: 0.5118\n",
            "Epoch 51 - Loss: 0.4972\n",
            "Epoch 52 - Loss: 0.5017\n",
            "Epoch 53 - Loss: 0.5074\n",
            "Epoch 54 - Loss: 0.5245\n",
            "Epoch 55 - Loss: 0.4992\n",
            "Epoch 56 - Loss: 0.5035\n",
            "Epoch 57 - Loss: 0.5156\n",
            "Epoch 58 - Loss: 0.5255\n",
            "Epoch 59 - Loss: 0.5008\n",
            "Epoch 60 - Loss: 0.5202\n",
            "Epoch 61 - Loss: 0.5123\n",
            "Epoch 62 - Loss: 0.5089\n",
            "Epoch 63 - Loss: 0.4897\n",
            "Epoch 64 - Loss: 0.5031\n",
            "Epoch 65 - Loss: 0.5105\n",
            "Epoch 66 - Loss: 0.4917\n",
            "Epoch 67 - Loss: 0.4949\n",
            "Epoch 68 - Loss: 0.4994\n",
            "Epoch 69 - Loss: 0.5191\n",
            "Epoch 70 - Loss: 0.5310\n",
            "Epoch 71 - Loss: 0.4927\n",
            "Epoch 72 - Loss: 0.4855\n",
            "Epoch 73 - Loss: 0.5121\n",
            "Epoch 74 - Loss: 0.5084\n",
            "Epoch 75 - Loss: 0.5129\n",
            "Epoch 76 - Loss: 0.5049\n",
            "Epoch 77 - Loss: 0.5164\n",
            "Epoch 78 - Loss: 0.5167\n",
            "Epoch 79 - Loss: 0.4992\n",
            "Epoch 80 - Loss: 0.4876\n",
            "Epoch 81 - Loss: 0.4947\n",
            "Epoch 82 - Loss: 0.5076\n",
            "Epoch 83 - Loss: 0.5246\n",
            "Epoch 84 - Loss: 0.5128\n",
            "Epoch 85 - Loss: 0.4911\n",
            "Epoch 86 - Loss: 0.4913\n",
            "Epoch 87 - Loss: 0.4875\n",
            "Epoch 88 - Loss: 0.5273\n",
            "Epoch 89 - Loss: 0.4981\n",
            "Epoch 90 - Loss: 0.4981\n",
            "Epoch 91 - Loss: 0.4984\n",
            "Epoch 92 - Loss: 0.4904\n",
            "Epoch 93 - Loss: 0.4921\n",
            "Epoch 94 - Loss: 0.5175\n",
            "Epoch 95 - Loss: 0.4895\n",
            "Epoch 96 - Loss: 0.4891\n",
            "Epoch 97 - Loss: 0.4895\n",
            "Epoch 98 - Loss: 0.4911\n",
            "Epoch 99 - Loss: 0.4860\n",
            "Epoch 100 - Loss: 0.5048\n",
            "Epoch 101 - Loss: 0.4804\n",
            "Epoch 102 - Loss: 0.5163\n",
            "Epoch 103 - Loss: 0.4833\n",
            "Epoch 104 - Loss: 0.4865\n",
            "Epoch 105 - Loss: 0.4881\n",
            "Epoch 106 - Loss: 0.4987\n",
            "Epoch 107 - Loss: 0.5211\n",
            "Epoch 108 - Loss: 0.5072\n",
            "Epoch 109 - Loss: 0.5130\n",
            "Epoch 110 - Loss: 0.4894\n",
            "Epoch 111 - Loss: 0.4851\n",
            "Epoch 112 - Loss: 0.4847\n",
            "Epoch 113 - Loss: 0.4915\n",
            "Epoch 114 - Loss: 0.5048\n",
            "Epoch 115 - Loss: 0.5007\n",
            "Epoch 116 - Loss: 0.4944\n",
            "Epoch 117 - Loss: 0.4973\n",
            "Epoch 118 - Loss: 0.4837\n",
            "Epoch 119 - Loss: 0.5137\n",
            "Epoch 120 - Loss: 0.5017\n",
            "Epoch 121 - Loss: 0.5194\n",
            "Epoch 122 - Loss: 0.4864\n",
            "Epoch 123 - Loss: 0.4890\n",
            "Epoch 124 - Loss: 0.4992\n",
            "Epoch 125 - Loss: 0.4946\n",
            "Epoch 126 - Loss: 0.4860\n",
            "Epoch 127 - Loss: 0.5089\n",
            "Epoch 128 - Loss: 0.4947\n",
            "Epoch 129 - Loss: 0.5342\n",
            "Epoch 130 - Loss: 0.5005\n",
            "Epoch 131 - Loss: 0.4962\n",
            "Epoch 132 - Loss: 0.4801\n",
            "Epoch 133 - Loss: 0.4879\n",
            "Epoch 134 - Loss: 0.4856\n",
            "Epoch 135 - Loss: 0.4820\n",
            "Epoch 136 - Loss: 0.4845\n",
            "Epoch 137 - Loss: 0.4863\n",
            "Epoch 138 - Loss: 0.4877\n",
            "Epoch 139 - Loss: 0.5121\n",
            "Epoch 140 - Loss: 0.4983\n",
            "Epoch 141 - Loss: 0.4820\n",
            "Epoch 142 - Loss: 0.4856\n",
            "Epoch 143 - Loss: 0.4876\n",
            "Epoch 144 - Loss: 0.4816\n",
            "Epoch 145 - Loss: 0.4941\n",
            "Epoch 146 - Loss: 0.5317\n",
            "Epoch 147 - Loss: 0.4953\n",
            "Epoch 148 - Loss: 0.5124\n",
            "Epoch 149 - Loss: 0.5102\n",
            "Epoch 150 - Loss: 0.5121\n",
            "Epoch 151 - Loss: 0.4706\n",
            "Epoch 152 - Loss: 0.5328\n",
            "Epoch 153 - Loss: 0.4974\n",
            "Epoch 154 - Loss: 0.4748\n",
            "Epoch 155 - Loss: 0.5176\n",
            "Epoch 156 - Loss: 0.4875\n",
            "Epoch 157 - Loss: 0.4977\n",
            "Epoch 158 - Loss: 0.4884\n",
            "Epoch 159 - Loss: 0.5144\n",
            "Epoch 160 - Loss: 0.4854\n",
            "Epoch 161 - Loss: 0.4832\n",
            "Epoch 162 - Loss: 0.4998\n",
            "Epoch 163 - Loss: 0.4982\n",
            "Epoch 164 - Loss: 0.4882\n",
            "Epoch 165 - Loss: 0.4771\n",
            "Epoch 166 - Loss: 0.4814\n",
            "Epoch 167 - Loss: 0.4902\n",
            "Epoch 168 - Loss: 0.4841\n",
            "Epoch 169 - Loss: 0.5360\n",
            "Epoch 170 - Loss: 0.4925\n",
            "Epoch 171 - Loss: 0.4965\n",
            "Epoch 172 - Loss: 0.4906\n",
            "Epoch 173 - Loss: 0.4881\n",
            "Epoch 174 - Loss: 0.4767\n",
            "Epoch 175 - Loss: 0.4979\n",
            "Epoch 176 - Loss: 0.5115\n",
            "Epoch 177 - Loss: 0.5162\n",
            "Epoch 178 - Loss: 0.4777\n",
            "Epoch 179 - Loss: 0.4893\n",
            "Epoch 180 - Loss: 0.4887\n",
            "Epoch 181 - Loss: 0.4970\n",
            "Epoch 182 - Loss: 0.4868\n",
            "Epoch 183 - Loss: 0.4838\n",
            "Epoch 184 - Loss: 0.5044\n",
            "Epoch 185 - Loss: 0.5016\n",
            "Epoch 186 - Loss: 0.4783\n",
            "Epoch 187 - Loss: 0.4950\n",
            "Epoch 188 - Loss: 0.4912\n",
            "Epoch 189 - Loss: 0.4797\n",
            "Epoch 190 - Loss: 0.4770\n",
            "Epoch 191 - Loss: 0.4775\n",
            "Epoch 192 - Loss: 0.4790\n",
            "Epoch 193 - Loss: 0.4808\n",
            "Epoch 194 - Loss: 0.4963\n",
            "Epoch 195 - Loss: 0.4800\n",
            "Epoch 196 - Loss: 0.4771\n",
            "Epoch 197 - Loss: 0.5016\n",
            "Epoch 198 - Loss: 0.4901\n",
            "Epoch 199 - Loss: 0.4846\n",
            "Epoch 200 - Loss: 0.5152\n",
            "Epoch 201 - Loss: 0.4830\n",
            "Epoch 202 - Loss: 0.4859\n",
            "Epoch 203 - Loss: 0.4986\n",
            "Epoch 204 - Loss: 0.4839\n",
            "Epoch 205 - Loss: 0.4742\n",
            "Epoch 206 - Loss: 0.4715\n",
            "Epoch 207 - Loss: 0.4961\n",
            "Epoch 208 - Loss: 0.4892\n",
            "Epoch 209 - Loss: 0.4929\n",
            "Epoch 210 - Loss: 0.5020\n",
            "Epoch 211 - Loss: 0.4801\n",
            "Epoch 212 - Loss: 0.4883\n",
            "Epoch 213 - Loss: 0.4924\n",
            "Epoch 214 - Loss: 0.5017\n",
            "Epoch 215 - Loss: 0.4721\n",
            "Epoch 216 - Loss: 0.5072\n",
            "Epoch 217 - Loss: 0.4784\n",
            "Epoch 218 - Loss: 0.4942\n",
            "Epoch 219 - Loss: 0.4886\n",
            "Epoch 220 - Loss: 0.4747\n",
            "Epoch 221 - Loss: 0.4881\n",
            "Epoch 222 - Loss: 0.4762\n",
            "Epoch 223 - Loss: 0.4887\n",
            "Epoch 224 - Loss: 0.4956\n",
            "Epoch 225 - Loss: 0.4783\n",
            "Epoch 226 - Loss: 0.4786\n",
            "Epoch 227 - Loss: 0.4774\n",
            "Epoch 228 - Loss: 0.5143\n",
            "Epoch 229 - Loss: 0.4663\n",
            "Epoch 230 - Loss: 0.5009\n",
            "Epoch 231 - Loss: 0.4827\n",
            "Epoch 232 - Loss: 0.4951\n",
            "Epoch 233 - Loss: 0.4716\n",
            "Epoch 234 - Loss: 0.4758\n",
            "Epoch 235 - Loss: 0.4926\n",
            "Epoch 236 - Loss: 0.5200\n",
            "Epoch 237 - Loss: 0.4872\n",
            "Epoch 238 - Loss: 0.5163\n",
            "Epoch 239 - Loss: 0.5065\n",
            "Epoch 240 - Loss: 0.4999\n",
            "Epoch 241 - Loss: 0.4950\n",
            "Epoch 242 - Loss: 0.4963\n",
            "Epoch 243 - Loss: 0.5121\n",
            "Epoch 244 - Loss: 0.4916\n",
            "Epoch 245 - Loss: 0.4999\n",
            "Epoch 246 - Loss: 0.4895\n",
            "Epoch 247 - Loss: 0.5102\n",
            "Epoch 248 - Loss: 0.4912\n",
            "Epoch 249 - Loss: 0.4856\n",
            "Epoch 250 - Loss: 0.5156\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "tokens = torch.tensor(quantized_tokens[:1000], dtype=torch.long)\n",
        "dataset = TensorDataset(tokens)\n",
        "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "optimizer = torch.optim.Adam(rq_transformer.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(100):\n",
        "    total_loss = 0\n",
        "    for (x,) in loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = rq_transformer(x, return_loss=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} - Loss: {total_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "samples = []\n",
        "\n",
        "for _ in range(batch_size):\n",
        "    sample = rq_transformer.generate()  # <- make sure these match your model\n",
        "    samples.append(sample.squeeze(0).cpu().numpy())  # shape (49, 3)\n",
        "\n",
        "generated_tokens = np.stack(samples, axis=0)  # shape: (8, 49, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated tokens shape: (4, 49, 4)\n"
          ]
        }
      ],
      "source": [
        "print(\"Generated tokens shape:\", generated_tokens.shape)  # (8, 49, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transformer_tokens_to_latents_batch(generated_tokens, quantizer):\n",
        "    \"\"\"\n",
        "    Converts RQTransformer-generated token indices (B, 49, 3) into quantized latent tensor (B, 7, 7, latent_dim)\n",
        "    \"\"\"\n",
        "    batch_size, seq_len, num_quantizers = generated_tokens.shape\n",
        "    h = w = int(seq_len ** 0.5)\n",
        "    latent_dim = quantizer.embedding_dim\n",
        "\n",
        "    quantized_latents = np.zeros((batch_size, seq_len, latent_dim), dtype=np.float32)\n",
        "\n",
        "    for i in range(num_quantizers):\n",
        "        codebook = quantizer.embeddings[i].numpy().T  # (num_embeddings, embedding_dim)\n",
        "        indices = generated_tokens[:, :, i]  # (B, 49)\n",
        "        # vectorized gather\n",
        "        embeddings = codebook[indices]  # (B, 49, latent_dim)\n",
        "        quantized_latents += embeddings\n",
        "\n",
        "    quantized_latents = quantized_latents.reshape(batch_size, h, w, latent_dim)\n",
        "    return quantized_latents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 1: Convert transformer output to latent vectors\n",
        "decoder_input = transformer_tokens_to_latents_batch(generated_tokens, quantizer)  # (B, 7, 7, 4)\n",
        "decoder_input_tensor = tf.convert_to_tensor(decoder_input, dtype=tf.float32)\n",
        "\n",
        "# Step 2: Decode\n",
        "decoder = vqvae_trainer.rvqvae.get_layer(\"decoder\")\n",
        "generated_images = decoder(decoder_input_tensor)  # (B, 28, 28, 1)\n",
        "\n",
        "# Step 3: Visualize the batch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(batch_size):\n",
        "    plt.subplot(1, batch_size, i+1)\n",
        "    plt.imshow(generated_images[i].numpy().squeeze(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([4, 28, 28, 1])"
            ]
          },
          "execution_count": 315,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shape(generated_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "real_images = tf.convert_to_tensor(x_test_scaled[:1000], dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing real images...\n",
            "Preprocessing generated images...\n",
            "Processing real images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting features: 100%|██████████| 32/32 [01:00<00:00,  1.89s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing generated images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting features: 100%|██████████| 32/32 [01:01<00:00,  1.93s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FID Score: 22.87\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from scipy.linalg import sqrtm\n",
        "from tqdm import tqdm\n",
        "\n",
        "def preprocess_images(images, target_size=(299, 299)):\n",
        "\n",
        "    if isinstance(images, np.ndarray):\n",
        "        images = tf.convert_to_tensor(images)\n",
        "\n",
        "    if images.shape[-1] == 1:\n",
        "        images = tf.image.grayscale_to_rgb(images)\n",
        "\n",
        "    images = tf.image.resize(images, target_size)\n",
        "\n",
        "    return images.numpy()\n",
        "\n",
        "def get_inception_features(images, model, batch_size=32):\n",
        "\n",
        "    features = []\n",
        "    for i in tqdm(range(0, len(images), batch_size), desc=\"Extracting features\"):\n",
        "        batch = images[i:i+batch_size]\n",
        "        features.append(model.predict(batch, verbose=0))\n",
        "    return np.concatenate(features, axis=0)\n",
        "\n",
        "def compute_fid(real_features, gen_features):\n",
        "\n",
        "    mu_real, sigma_real = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
        "    mu_gen, sigma_gen = np.mean(gen_features, axis=0), np.cov(gen_features, rowvar=False)\n",
        "\n",
        "    ssdiff = np.sum((mu_real - mu_gen)**2)\n",
        "    covmean = sqrtm(sigma_real.dot(sigma_gen))\n",
        "\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "\n",
        "    fid = ssdiff + np.trace(sigma_real + sigma_gen - 2*covmean)\n",
        "    return fid\n",
        "\n",
        "def calculate_fid(real_images, gen_images, batch_size=32):\n",
        "\n",
        "    inception = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))\n",
        "\n",
        "    print(\"Preprocessing real images...\")\n",
        "    real_processed = preprocess_images(real_images)\n",
        "    print(\"Preprocessing generated images...\")\n",
        "    gen_processed = preprocess_images(gen_images)\n",
        "\n",
        "    print(\"Processing real images...\")\n",
        "    real_features = get_inception_features(real_processed, inception, batch_size)\n",
        "    print(\"Processing generated images...\")\n",
        "    gen_features = get_inception_features(gen_processed, inception, batch_size)\n",
        "\n",
        "    return compute_fid(real_features, gen_features)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    if isinstance(real_images, tf.Tensor):\n",
        "        real_images = real_images.numpy()\n",
        "    if isinstance(generated_images, tf.Tensor):\n",
        "        generated_images = generated_images.numpy()\n",
        "\n",
        "    fid_score = calculate_fid(real_images, reconstructions_test)\n",
        "    print(f\"FID Score: {fid_score:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(49, 3)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shape(generated_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot of Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save(\"total_loss_woEMA_n2.npy\", history.history[\"loss\"])\n",
        "np.save(\"reconstruction_loss_woEMA_n2.npy\", history.history[\"reconstruction_loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming history object has been trained and you want to plot total_loss\n",
        "total_loss = history.history[\"loss\"]  # Replace with the correct loss name if necessary\n",
        "#reconstruction_loss = history.history[\"reconstruction_loss\"]  # Replace with actual name if available\n",
        "#rvqvae_loss = history.history[\"rvqvae_loss\"]  # Replace with actual name if available\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(total_loss, label=\"Total Loss\", alpha=0.7)\n",
        "#plt.plot(reconstruction_loss, label=\"Reconstruction Loss\", alpha=0.7)\n",
        "#plt.plot(rvqvae_loss, label=\"RVQ-VAE Loss\", alpha=0.7)\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Model Training Losses\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgH4xNZsUUh6"
      },
      "source": [
        "The figure above shows that the discrete codes have been able to capture some\n",
        "regularities from the dataset. Now, how do we sample from this codebook to create\n",
        "novel images? Since these codes are discrete and we imposed a categorical distribution\n",
        "on them, we cannot use them yet to generate anything meaningful until we can generate likely\n",
        "sequences of codes that we can give to the decoder.\n",
        "\n",
        "The authors use a PixelCNN to train these codes so that they can be used as powerful priors to\n",
        "generate novel examples. PixelCNN was proposed in\n",
        "[Conditional Image Generation with PixelCNN Decoders](https://arxiv.org/abs/1606.05328)\n",
        "by van der Oord et al. We borrow the implementation from\n",
        "[this PixelCNN example](https://keras.io/examples/generative/pixelcnn/). It's an autoregressive\n",
        "generative model where the outputs are conditional on the prior ones. In other words, a PixelCNN\n",
        "generates an image on a pixel-by-pixel basis. For the purpose in this example, however, its task\n",
        "is to generate code book indices instead of pixels directly. The trained VQ-VAE decoder is used\n",
        "to map the indices generated by the PixelCNN back into the pixel space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtuqlg-AUUh6"
      },
      "source": [
        "## PixelCNN hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "7W-To9U9UUh6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape of the PixelCNN: (7, 7)\n"
          ]
        }
      ],
      "source": [
        "num_residual_blocks = 2\n",
        "num_pixelcnn_layers = 2\n",
        "pixelcnn_input_shape = encoded_outputs.shape[1:-1]\n",
        "print(f\"Input shape of the PixelCNN: {pixelcnn_input_shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZFHS_8hUUh6"
      },
      "source": [
        "This input shape represents the reduction in the resolution performed by the encoder. With \"same\" padding,\n",
        "this exactly halves the \"resolution\" of the output shape for each stride-2 convolution layer. So, with these\n",
        "two layers, we end up with an encoder output tensor of 7x7 on axes 2 and 3, with the first axis as the batch\n",
        "size and the last axis being the code book embedding size. Since the quantization layer in the autoencoder\n",
        "maps these 7x7 tensors to indices of the code book, these output layer axis sizes must be matched by the\n",
        "PixelCNN as the input shape. The task of the PixelCNN for this architecture is to generate _likely_ 7x7\n",
        "arrangements of codebook indices.\n",
        "\n",
        "Note that this shape is something to optimize for in larger-sized image domains, along with the code\n",
        "book sizes. Since the PixelCNN is autoregressive, it needs to pass over each codebook index sequentially\n",
        "in order to generate novel images from the codebook. Each stride-2 (or rather more correctly a\n",
        "stride (2, 2)) convolution layer will divide the image generation time by four. Note, however, that there\n",
        "is probably a lower bound on this part: when the number of codes for the image to reconstruct is too small,\n",
        "it has insufficient information for the decoder to represent the level of detail in the image, so the\n",
        "output quality will suffer. This can be amended at least to some extent by using a larger code book.\n",
        "Since the autoregressive part of the image generation procedure uses codebook indices, there is far less of\n",
        "a performance penalty on using a larger code book as the lookup time for a larger-sized code from a larger\n",
        "code book is much smaller in comparison to iterating over a larger sequence of code book indices, although\n",
        "the size of the code book does impact on the batch size that can pass through the image generation procedure.\n",
        "Finding the sweet spot for this trade-off can require some architecture tweaking and could very well differ\n",
        "per dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmGoin7xUUh6"
      },
      "source": [
        "## PixelCNN model\n",
        "\n",
        "Majority of this comes from\n",
        "[this example](https://keras.io/examples/generative/pixelcnn/).\n",
        "\n",
        "## Notes\n",
        "Thanks to [Rein van 't Veer](https://github.com/reinvantveer) for improving this example with\n",
        "copy-edits and minor code clean-ups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFr5XEe1UUh6"
      },
      "outputs": [],
      "source": [
        "# The first layer is the PixelCNN layer. This layer simply\n",
        "# builds on the 2D convolutional layer, but includes masking.\n",
        "class PixelConvLayer(layers.Layer):\n",
        "    def __init__(self, mask_type, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mask_type = mask_type\n",
        "        self.conv = layers.Conv2D(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Build the conv2d layer to initialize kernel variables\n",
        "        self.conv.build(input_shape)\n",
        "        # Use the initialized kernel to create the mask\n",
        "        kernel_shape = self.conv.kernel.get_shape()\n",
        "        self.mask = np.zeros(shape=kernel_shape)\n",
        "        self.mask[: kernel_shape[0] // 2, ...] = 1.0\n",
        "        self.mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n",
        "        if self.mask_type == \"B\":\n",
        "            self.mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self.conv.kernel.assign(self.conv.kernel * self.mask)\n",
        "        return self.conv(inputs)\n",
        "\n",
        "\n",
        "# Next, we build our residual block layer.\n",
        "# This is just a normal residual block, but based on the PixelConvLayer.\n",
        "class ResidualBlock(keras.layers.Layer):\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv1 = keras.layers.Conv2D(\n",
        "            filters=filters, kernel_size=1, activation=\"relu\"\n",
        "        )\n",
        "        self.pixel_conv = PixelConvLayer(\n",
        "            mask_type=\"B\",\n",
        "            filters=filters // 2,\n",
        "            kernel_size=3,\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "        )\n",
        "        self.conv2 = keras.layers.Conv2D(\n",
        "            filters=filters, kernel_size=1, activation=\"relu\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pixel_conv(x)\n",
        "        x = self.conv2(x)\n",
        "        return keras.layers.add([inputs, x])\n",
        "\n",
        "\n",
        "pixelcnn_inputs = keras.Input(shape=pixelcnn_input_shape, dtype=tf.int32)\n",
        "ohe = tf.one_hot(pixelcnn_inputs, vqvae_trainer.num_embeddings)\n",
        "x = PixelConvLayer(\n",
        "    mask_type=\"A\", filters=128, kernel_size=7, activation=\"relu\", padding=\"same\"\n",
        ")(ohe)\n",
        "\n",
        "for _ in range(num_residual_blocks):\n",
        "    x = ResidualBlock(filters=128)(x)\n",
        "\n",
        "for _ in range(num_pixelcnn_layers):\n",
        "    x = PixelConvLayer(\n",
        "        mask_type=\"B\",\n",
        "        filters=128,\n",
        "        kernel_size=1,\n",
        "        strides=1,\n",
        "        activation=\"relu\",\n",
        "        padding=\"valid\",\n",
        "    )(x)\n",
        "\n",
        "out = keras.layers.Conv2D(\n",
        "    filters=vqvae_trainer.num_embeddings, kernel_size=1, strides=1, padding=\"valid\"\n",
        ")(x)\n",
        "\n",
        "pixel_cnn = keras.Model(pixelcnn_inputs, out, name=\"pixel_cnn\")\n",
        "pixel_cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms9lnXHbUUh6"
      },
      "source": [
        "## Prepare data to train the PixelCNN\n",
        "\n",
        "We will train the PixelCNN to learn a categorical distribution of the discrete codes.\n",
        "First, we will generate code indices using the encoder and vector quantizer we just\n",
        "trained. Our training objective will be to minimize the crossentropy loss between these\n",
        "indices and the PixelCNN outputs. Here, the number of categories is equal to the number\n",
        "of embeddings present in our codebook (128 in our case). The PixelCNN model is\n",
        "trained to learn a distribution (as opposed to minimizing the L1/L2 loss), which is where\n",
        "it gets its generative capabilities from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Bt0Z-lXUUh6"
      },
      "outputs": [],
      "source": [
        "# Generate the codebook indices.\n",
        "encoded_outputs = encoder.predict(x_train_scaled)\n",
        "flat_enc_outputs = encoded_outputs.reshape(-1, encoded_outputs.shape[-1])\n",
        "codebook_indices = quantizer.get_code_indices(flat_enc_outputs)\n",
        "\n",
        "codebook_indices = codebook_indices.numpy().reshape(encoded_outputs.shape[:-1])\n",
        "print(f\"Shape of the training data for PixelCNN: {codebook_indices.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OeLNaiyUUh7"
      },
      "source": [
        "## PixelCNN training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7C9K15ZyUUh7"
      },
      "outputs": [],
      "source": [
        "pixel_cnn.compile(\n",
        "    optimizer=keras.optimizers.Adam(3e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "pixel_cnn.fit(\n",
        "    x=codebook_indices,\n",
        "    y=codebook_indices,\n",
        "    batch_size=128,\n",
        "    epochs=30,\n",
        "    validation_split=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUqlCGhXUUh7"
      },
      "source": [
        "We can improve these scores with more training and hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3p-FDj_UUh7"
      },
      "source": [
        "## Codebook sampling\n",
        "\n",
        "Now that our PixelCNN is trained, we can sample distinct codes from its outputs and pass\n",
        "them to our decoder to generate novel images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6csp1zDBUUh7"
      },
      "outputs": [],
      "source": [
        "# Create a mini sampler model.\n",
        "inputs = layers.Input(shape=pixel_cnn.input_shape[1:])\n",
        "outputs = pixel_cnn(inputs, training=False)\n",
        "categorical_layer = tfp.layers.DistributionLambda(tfp.distributions.Categorical)\n",
        "outputs = categorical_layer(outputs)\n",
        "sampler = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCQQ2Uo8UUh7"
      },
      "source": [
        "We now construct a prior to generate images. Here, we will generate 10 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2sxjkVWUUh7"
      },
      "outputs": [],
      "source": [
        "# Create an empty array of priors.\n",
        "batch = 10\n",
        "priors = np.zeros(shape=(batch,) + (pixel_cnn.input_shape)[1:])\n",
        "batch, rows, cols = priors.shape\n",
        "\n",
        "# Iterate over the priors because generation has to be done sequentially pixel by pixel.\n",
        "for row in range(rows):\n",
        "    for col in range(cols):\n",
        "        # Feed the whole array and retrieving the pixel value probabilities for the next\n",
        "        # pixel.\n",
        "        probs = sampler.predict(priors)\n",
        "        # Use the probabilities to pick pixel values and append the values to the priors.\n",
        "        priors[:, row, col] = probs[:, row, col]\n",
        "\n",
        "print(f\"Prior shape: {priors.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV07VNuKUUiJ"
      },
      "source": [
        "We can now use our decoder to generate the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJz1ajVVUUiJ"
      },
      "outputs": [],
      "source": [
        "# Perform an embedding lookup.\n",
        "pretrained_embeddings = quantizer.embeddings\n",
        "priors_ohe = tf.one_hot(priors.astype(\"int32\"), vqvae_trainer.num_embeddings).numpy()\n",
        "quantized = tf.matmul(\n",
        "    priors_ohe.astype(\"float32\"), pretrained_embeddings, transpose_b=True\n",
        ")\n",
        "quantized = tf.reshape(quantized, (-1, *(encoded_outputs.shape[1:])))\n",
        "\n",
        "# Generate novel images.\n",
        "decoder = vqvae_trainer.vqvae.get_layer(\"decoder\")\n",
        "generated_samples = decoder.predict(quantized)\n",
        "\n",
        "for i in range(batch):\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(priors[i])\n",
        "    plt.title(\"Code\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(generated_samples[i].squeeze() + 0.5)\n",
        "    plt.title(\"Generated Sample\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3dKOwOUUUiJ"
      },
      "source": [
        "We can enhance the quality of these generated samples by tweaking the PixelCNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFx3wFOtUUiJ"
      },
      "source": [
        "## Additional notes\n",
        "\n",
        "* After the VQ-VAE paper was initially released, the authors developed an exponential\n",
        "moving averaging scheme to update the embeddings inside the quantizer. If you're\n",
        "interested you can check out\n",
        "[this snippet](https://github.com/deepmind/sonnet/blob/master/sonnet/python/modules/nets/vqvae.py#L124).\n",
        "* To further enhance the quality of the generated samples,\n",
        "[VQ-VAE-2](https://arxiv.org/abs/1906.00446) was proposed that follows a cascaded\n",
        "approach to learn the codebook and to generate the images."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
